数据挖掘流程
	基本流程
		提出问题
		准备数据
		分析数据
		洞察结论
	拓展流程
		需求层
			目标确定
		数据层
			数据获取
			数据规整（清晰）
				清理、转换、合并、重塑
				数据重构、特征工程
			分析层
				描述性分析
				探索性分析
			输出层
				洞察结论 应用成果

============matplotlib=====================================

Python可视化库生态（拓展）
	Matplotlib 二维底层绘图库
		Seaborn 上层图表库，基于Matplotlib
	VTK 三维底层绘图库
		Mayavi 三维上层绘图库
	Web交互式图表库
		Bokeh：交互式图表库，Web端，基于D3
		Plotly：交互式图表库，Web端，基于D3


WEB前端可视化库(基于JavaScript)生态（拓展）
	D3.js：
		JS绘图底层库。https://d3js.org/
	Echarts：
		可视化图表。百度：http://echarts.baidu.com/
	AntV：
		可视化图表。阿里：https://antv.alipay.com/index.html
	可视化数据大屏：
		交互的实时数据可视化视屏墙。https://data.aliyun.com/visual/datav
	其他WEB前端绘图技术
		Flash
		canvas
		WebGL https://threejs.org/

折线图：plot
	pyplot.plot([0,2,4,6,8]) # 默认Y轴坐标
	pyplot.plot([0,2,4,6,8],[1,5,3,9,7]) 
	pyplot.show() #显示图片


	plot的参数：
		线条颜色，color='g'
		线条风格，linestyle='--'
		线条粗细，linewidth=5.0
		标记风格，marker='o'
		标记颜色，markerfacecolor='b'
		标记尺寸，markersize=20
		透明度，alpha=0.5

			eurcny = [数据]
			date = [数据]
			plt.plot(
			    date, # x轴数据，日期
			    eurcny, # y轴数据，收盘价

			    color='r', # 线条颜色
			    linestyle='--', # 线条风格
			    linewidth=2, # 线条粗细

			    marker='o', # 标记风格
			    markerfacecolor='#ffff00', # 标记颜色
			    markersize=5, # 标记大小

			    alpha=0.5, # 透明度
			)
			
			plt.show()

散点图/气泡图：scatter
	x = [1,3,5,7,9,11,13,15,17]
	y = [2,-5,19,3,5,8,12,6,1]
	plt.scatter(x, y)
	plt.show()


	样式参数：
		s[100,200,300,400...]
			表示每个点的大小，可以写一个数值和多个数值，如果写的数量小于点的数量，会循环取值，大于点的数量只会取一部分数值


柱状图：bar
	width :柱子的宽度，默认0.8 设置时不大于1
条形图：barh 
	相当于柱状图 x,y 轴互换
	height :柱子的宽度，默认0.8 设置时不大于1
	yticks:设置Y轴的坐标数据,这时实际上是设置的x轴的数据

	x = [1,2,3,4,5]
	y = [3,6,1,8,2]
	plt.bar(x, y)
	plt.show()
	plt.barh(x,y)
	plt.yticks(x,['a','b','c','d','e'])
	plt.show()	
	
	多个柱状图在一起显示的时候，更改x轴数据的显示要计算好bar的宽度

饼状图：pie
	p = [15,30,45,10]
	plt.pie(p)
	plt.show()

	参数：
		labels = 名称列表,  # 名称，和数据在列表的的位置要对应
	    explode=(0,0.05,0,0,0,0,0,0,0),  # 突出块，突出比例
	    autopct='%1.1f%%',  # 显示百分比方式
	    shadow=False,  # 阴影效果
	    startangle=250,  # 饼图起始的角度,度数,默认0为右侧水平180度开始，逆时针旋转

	# 国名
	mark = ['America','China','India','Saudi','Russia','Japan','Britain','Germany','France']
	# 各国占9国总军费的比例
	percent = [0.5548467,0.14444868,0.05094268,0.04846696,0.046753,0.04418206,0.04161112,0.03799276,0.03075605]

	plt.pie(
	    percent,  # 百分比
	    labels = mark,  # 名称
	    explode=(0,0.05,0,0,0,0,0,0,0),  # 突出块，突出比例
	    autopct='%1.1f%%',  # 显示百分比方式
	    shadow=False,  # 阴影效果
	    startangle=25 0,  # 饼图起始的角度,度数,默认0为右侧水平180度开始，逆时针旋转
	)

	plt.axis('equal') #正圆形饼图,x/y轴尺寸相等.默认是扁图,

	plt.show()

直方图：hist
	h1 = [ 88.2,  83.5,  68.8,  85.4,  78.6,  69.3,  60.6,  91.2,  52.7,
        85.9,  57.1,  68. ,  66.6,  78.2,  78.8,  85. ,  89.1,  74.4,
        93.6,  75.7,  54.3,  55. ,  90.9,  79.4,  94.4,  86.7,  82.4,
        76.7,  78.7,  72.3,  83.9,  78.6,  80. ,  70.5,  87.1,  80.3,
        87.9,  65.1,  67.4,  61.5,  49.7,  77.1,  91.4,  72. ,  61.5,
        73.9,  76.9,  88.2,  51.2,  53.9]
        plt.hist(h1)

		plt.show()

	plt.hist(
    h1,  # 直方图数据
    10,  # 直方个数
    normed=1,  # 默认0 数据出现个数，1 出现个数归一化为出现的频率(频率=出现次数/总数)
    histtype='bar',  # 直方图样式：默认bar，stepfilled填充颜色，step不填充只有线条
    facecolor='b',  # 直方图颜色
    edgecolor = 'g',  # 直方图边框颜色
    alpha=0.3,
	)

	# 直方图叠加
	plt.hist(h2, 10, normed=1, histtype='bar', alpha = 0.3)

	plt.show()

箱线图：boxplot
	用作显示一组数据离散情况的统计图表，常用作多组数据的综合统计比较

	四分位数：
		第一四分位数/Q1/较小四分位数
			该样本中所有数值由小到大排列后第25%的数
		第二四分位数/Q2/中位数
			该样本中所有数值由小到大排列后第50%的数
		第三四分位数/Q3/较大四分位数
			该样本中所有数值由小到大排列后第75%的数

	5个统计量：
		最大值：上边线
		Q3
		Q2
		Q1
		最小值：下边线

	异常值：
		Q3和Q1的差
		大于Q3 1.5倍四分位数差的值，或者小于Q1 1.5倍四分位数差的值

热力图：imshow
	a = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9]
	]
	plt.imshow(a)

	plt.show()

	参数：
		cmap='gray',  # 配色，gray灰度
	    origin='lower', # 水平翻转，默认upper,lower
	    interpolation='lanczos', # 渲染，模糊
		plt.colorbar() #侧栏

figure父对象：
	figure父对象是与用户交互的整个窗口
	用于在同一文件内绘制多个图像时的区分

axes子对象：
	figure对象中包含一个或多个axes(ax)子对象
	每个ax子对象都是一个拥有自己独立坐标系的绘图区域
	用于在同一图像内绘制多个子图像的区分		

创建多个父对象：
	plt.figure(num, figsize = (width, heigh))
	num：图像编号
	width，height：图像宽度，高度

创建多个子对象
	plt.subplot(nrows, ncols, plot_number)
	nrows，横轴数量，类似表格的 行
	ncols，纵轴数量，类似表格的 列
	plot_number，当前绘制的ax子图位置，横轴x,纵轴y

设置标题：set_title('爱我中华')

父对象子对象结合：
	# 图表1
	plt.figure(1) # 创建figure父窗口，默认编号为1

	plt.subplot(121)
	plt.subplot(122) # 创建ax子窗口，1行2列，选中第2个
	plt.plot([1,3,2])

	# 图表2
	plt.figure(2)

	plt.subplot(131)
	plt.subplot(132)
	plt.subplot(133)
	plt.plot([1,2,3])

	plt.show()

图像组件：
	用于调整图像各组成部分的样式

	图表标题：
			plt.title(
		    'hello图表标题',
		    color = '#00ff00',
		    fontsize = 24,
		)
	坐标轴标注（名称）：
		plt.xlabel('X axis')
		plt.ylabel('Y轴标注')

	刻度设置和刻度标注：
		plt.yticks([1,3,6,9,12,15,18,20])  # 设置坐标刻度步长
		plt.xticks(
		    [0,1,2,5,8,10],  # 刻度设置
		    ['2000','2001','2002','2005','2008','2010'],  # 刻度标注
		    fontsize = 14,  # 文字大小
		    rotation = 90,  # 旋转角度
		)

	坐标范围：
		# plt.axis([-1,11,-2,12]) # X轴-1到11,Y轴-2到12
		plt.xlim([-1,11])  # x轴坐标范围：-1到11
		plt.ylim([-2,12])  # y轴坐标范围：-2到12

	图例：
		首先需要在plot()里面加上label（‘图例的名称’）
		plt.legend(
		    handles = [n1,n2],  # 给指定数据绘制图例
		    loc = 'upper right',  # 图例位置
		    frameon=  False  # 有无边框
			)
	网格：
		plt.grid()

	设置分辨率：
		plt.savefig('test', dpi = 600)  # dpi 分辨率，常用：72，300

数学计算展示图像：
	# 绘图
	plt.plot(x,y)

	###############

	# 组件

	# 标题，可以使用$引入部分latex文本排版语法和公式
	plt.title('线性 $y=ax+b$，非线性 $y=ax^{2}+bx+c$')  

	# 坐标轴标注，当字符串里有反斜杠等转义特殊字符时,字符串前加`r`,表示显示原始字符串
	plt.xlabel(r'X \axis')  

	###############

	# 操作轴线

	# gca，get corrent axis，获取轴
	ax = plt.gca()

	# 交换轴线
	# ax.xaxis.set_ticks_position('top')
	# ax.yaxis.set_ticks_position('right')

	# 去除上侧和右侧的空白轴线
	ax.spines['right'].set_color('none')
	ax.spines['top'].set_color('none')

	# 移位轴线
	ax.spines['bottom'].set_position(['data', -10])
	ax.spines['left'].set_position(['data', 0])

	###############

	# 添加注解标识

	# 标记点
	x0 = -2.5
	y0 = a * x0 + b
	ax.scatter(x0, y0, color='red')  # 绘制点

	# 标记线
	ax.plot(
	    [x0, x0],
	    [y0, -10],
	    'k--',
	)

	# 任意位置增加文本
	ax.text(
	    5,  # x轴
	    10,  # y轴
	    '第一象限',  # 显示文本内容
	    fontsize=16,  # 文字大小
	    rotation=30,  # 旋转角度
	)
	# 任意位置增加带箭头的注释文本
	ax.annotate(
	    r'$Linear\ function\ y=ax+b$',  #显示字符串，空格在$内不显示，用反斜杠转义
	    xy=(x0, y0),  # 箭头位置
	    xycoords = 'data',  # 相对默认坐标系偏移

	    xytext=(-150, 50),  # 文本位置
	    textcoords = 'offset points',  # 相对坐标，相对箭头原点偏移

	    arrowprops=dict(  # 字典类型，定义箭头样式
	        arrowstyle = 'fancy',  # 箭头样式，例如 -> <- |-| simple fancy
	        color = 'green',  # 箭头颜色
	        connectionstyle="arc3,rad=.2",  # 箭头弧度
	    )
	)

	plt.show()

三维图像：
	import numpy as np
	import matplotlib.pyplot as plt
	from mpl_toolkits.mplot3d import Axes3D  # 载入三维子库

	plt.rcParams['font.family'] = ['Arial Unicode MS', 'sans-serif']

	# GUI输出图像
	# %matplotlib qt5

	# 创建父对象
	fig=plt.figure()
	# 创建子对象（三维）
	ax=Axes3D(fig)

	# 各轴生成0-100的随机坐标数据20个
	x = np.random.randint(0, 100, 20)
	y = np.random.randint(0, 100, 20)
	z = np.random.randint(0, 100, 20)

	# 绘制散点图
	ax.scatter(x, y, z)
	# 绘制折线图
	ax.plot(x, y, z)

	# 坐标轴名称
	ax.set_xlabel('x轴')
	ax.set_ylabel('y轴')
	ax.set_zlabel('z轴')

	plt.show()

动画：
	import random

	import numpy as np
	import matplotlib.pyplot as plt
	from matplotlib.animation import FuncAnimation  # 载入动画子库

	# GUI输出，动画图像不能在网页展示
	%matplotlib qt5

	###########################3

	fig = plt.figure()
	ax = fig.add_subplot(111)

	line = []  # 供折线图追加数据

	# 动画每帧调用的函数
	def update(i):
	#     print(i)  # frame的值，随调用遍历

	#     # 绘制散点图
	#     s1 = random.randint(-10, 10)  # x轴坐标数据
	#     s2 = random.randint(-10, 10)  # y轴坐标数据
	#     ax.scatter(s1, s2)  # 绘图

	    # 绘制折线图
	    s = random.randint(-1, 1)  # 生成-1到1的随机数一个
	    line.append(s)  # 随机数追加至变量line
	    ax.plot(  # 绘图
	        np.array(line).cumsum(),  # y轴坐标，line转为数组并累加
	        color='red'
	    )

	# 动画方法
	ani = FuncAnimation(
	    fig,  # 动画应用的图像
	    update,  # 动画每帧都要调用的函数
	    frames = np.arange(1, 50), # 动画帧数，对GIF有效，值调用函数内的i可以获取。不需遍历可用整数如 frames = 50
	    interval = 100,  # 动画帧间隔，毫秒
	)

	# 动画保存为GIf图片
	ani.save('line.gif', dpi=80, writer='imagemagick')

	plt.show()

中文显示：
	matpoltlib默认不支持中文字符，因为默认设置字体是sans-serif英文字体不能显示汉字
	解决办法：
		import matplotlib as plt
		plt.rcParams['font.family'] = ['Arial Unicode MS', 'sans-serif'] #  全局设置支持中文字体，默认 sans-serif






===================numpy================================
没弄懂得地方：
	where(a>2)
	np.sort(b axsi=0)



Numpy是Python的开源数值计算库
	Numpy用于在大型、多维数组（矩阵）上执行数值运算
	Numpy是Scipy/Pandas/scikit-learn等科学计算、数据分析、机器学习库的基础库，也是Python数据挖掘的基础

numpy的优点：
	数组的运算
	矢量化运算
		优势：
			去掉元素间运算所需要的循环和细节处理
			运算速度快

array数组：
	n维数组对象，存储单一数据类型的多维数组，简称数组
	接收一切序列型对象，如list tuple  
	默认数组值类型相同，创建时自动指定数据类型(内存占用最大的值类型）
		np.bool			布尔值
		np.int			整型
		np.float		浮点型
		np.unicode_		Unicode所有字符，字节数平台决定

array数组对象属性：
	.dtype	对象的元素类型
	.size	对象元素的个数，相当于.shape中的n*m的值
	.shape	轴，数组形状，对于矩阵，n行m列
	.ndim	秩，相当于有多少个维度

数据的维度应用：
	0维，单个数值，文本数据
	1维，一维list列表，一维ndarray数组
	2维，表格，CSV，关系型数据库
		可以看做简化版的多维数据格式（行列键值对）
	多维，能组织表达一切
		数组嵌套形式：多层list或array嵌套
		标签形式:XML，HTML
		键值对形式:
			字典：Python专用
			通用：
				JSON,有数据类型的键值对(应用于不同系统间的信息交互,例如移动端和服务器的API接口交互)
				YAML,TOML等,无数据类型的键值对(系统/软件的配置文件)
				非关系型数据库,MongoDB等
numpy创建特定数组：
	为了实现某些运算，需要快速构造符合要求的大数组
	numpy函数生成的数组，如果不指定类型，除了arange是整型以外，其他全是浮点型

	np.arange(n)	
		类似range()函数(递增的整数序列)，元素从0到n-1
	np.linspace()	
		根据起止数据等间距填充数据形成数组
	np.ones(shape)	
		根据shape生成一个全1数组，shape是元组类型
	np.ones_like(ndarray)	
		以另一个数组为参数，根据其形状和dtype创建全1数组
	np.zeros(shape)	
		根据shape生成一个全0数组，shape是元组类型
	np.zeros_like(ndarray)	以另一个数组为参数，
		根据其形状和dtype创建全0数组
	np.empty(shape)	
		创建新数组只分配内存空间，随意填充一些垃圾值
	np.empty_like(ndarray)
		以另一个数组为参数，根据其形状和dtype创建填充值数组
	np.full(shape,val)	
		根据shape生成一个数组，每个元素都是val
	np.full_like(a,val)	
		根据数组a的形状生成一个全 val 数组
	np.eye(n)
		创建一个正方的n*n单位矩阵，对角线为1，其余为0
	np.diag(list)	
		创建一个正方形矩阵，对角线为参数值

使用numpy.random 随机数创建特定数组
	.rand(d0,d1,..dn)	
		创建d0-dn维度的均匀分布的随机数数组，浮点数，范围从0-1
	.uniform(low,high,(size))	
		产生具有均匀分布的数组，low起始值，high结束值，size形状
	.randint(low,high,(shape))	
		从给定上下限范围选取随机数整数，范围是low,high，形状是shape
	.randn(d0,d1,..dn)	
		创建d0-dn维度的标准正态分布随机数，浮点数，平均数0，标准差1
	.normal(loc,scale,(size))	
		从指定正态分布中随机抽取样本，分布中心是loc（概率分布的均值）,标准差是scale，形状是size
	.seed(s)	
		随机数种子，s是给定的种子值。因为计算机生成的是伪随机数，所以通过设定相同的随机数种子，可以每次生成相同的随机数、

查询修改：
	索引：获取数组中特定位置的元素
	切片：获取数组中特定元素的子集
		一维索引和切片
		多维索引和切片
		布尔索引和切片
	根据值获取索引

	data = np.arange(28).reshape(7, 4)：
		生成28个数7行，4列的数组

一维数组的索引和切片：
	和列表类似
多维数组的索引和切片：
	索引：
		a[1,2,3]:取第一维度第一个第二维度第二个第三维度第三个
	切片：
		a[:,0:2,1:3]：按","分割，第一个维度按第一个切片以此类推

布尔型索引：
	names = np.array(['张三','李四','王五','张三','王五','李四','李四'])
	data = np.arange(28).reshape(7, 4)
	
	names == '张三'
	--->array([ True, False, False,  True, False, False, False])

	names[names == '张三']
	-->array(['张三', '张三'], dtype='<U2')

	data[names == '张三']
	-->array([[ 0,  1,  2,  3],
       [12, 13, 14, 15]])
       相当于取了和张三索引一样的值


	# 可将布尔型数组跟切片、整数、整数序列混合使用
	data[names == '张三', 2:]
	-->array([[ 2,  3],
       [14, 15]])
       先按张三的索引取值再切片

    逻辑运算：
    	组合多个布尔型索引，进行逻辑运算
		组合条件，逻辑运算符：& 且，| 或，非（!= 或 ~）
    	mask = (names == '张三') | (names == '王五')
    	data(mask)
    	-->array([[ 0,  1,  2,  3],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15],
       [16, 17, 18, 19]])
       按张三和王五的索引一起取值

数组元素的修改：
	无论索引、切片还是布尔索引，只要选中元素，为其赋值即可修改

数组变换：
	数据维度变换、类型变换是产生新ndarray数组的进阶方式
	.reshape(shape)	
		返回一个shape形状的数组，修改视图，不改变原数组，
	.resize(shape)	
		与.reshape()功能相同，但修改原数组
	.flatten()
		对数组降维，返回折叠后的一维数组，修改视图，不改变原数组
类型变换：astype
	new_a = a.astype(new_type)，只修改视图，不改变原数组

	np.bool		布尔值
	np.int		整型
	np.float	浮点型
	np.complex	复数
	np.object	对象
	np.string_	ASCII字符
	np.unicode_	Unicode所有字符，字节数平台决定

数组运算：
	都会元素相运算

	abs	绝对值
	sqrt	平方根，等价于 arr ** 0.5
	square	平方，等价于 arr ** 2
	logical_not	计算各元素not x的真值，等价于 -arr
	sign	计算每个元素的符号：，1(正数)，0(零)，-1(负数)
	modf	分别返回小数数和整数部分的数组
	log, log10, log2, log1p	自然对数（底数为e），底数为10的对数，底数为2的对数和 log(1 + x)
	exp	以e为底的指数函数 ex，2.71828 ** x
	cos, cosh, sin sinh, tan, tanh	三角函数，普通型和双曲型
	arccos, arccosh, arcsin, arcsinh, arctan, arctanh	反三角函数

数组统计运算:
	

	sum	求和
	cumsum	累加
	cumprod	累乘
		相当于每次多加一个元素得到的值生成的新数组
	diff	相邻数组元素的差值
	mean	算术平均值
	average	加权平均值，weights加权值，不设为等权重
	var, std	方差：各数与平均数之差的平方的平均数
	标准差：方差平方根
	median	中位数
	min, max	最大值和最小值
	ptp	极差，最大值与最小值的差
	argmin, argmax	返回选中值1维扁平化后的最小值／最大值的索引

		以上运算中都可以带上参数：axis  表示从内到外运算几维
			c = array([[0, 1, 2],
				       [3, 4, 5],
				       [6, 7, 8]])
			np.sum(c)
			-->36
			np.sum(c,axis=1)
			-->array([ 3, 12, 21])

用于布尔型数组的方法
	统计运算中，布尔值会被强制转换为1和0，可以使用sum()对布尔型数组中的True值计数

	# 计数非0值个数
	np.count_nonzero(arr > 0)
	bools.any() #测试数组中是否存在一个或多个True
	bools.all() #数组中所有值是否都是True
	any() 和 all() 也可用于非布尔型数组，所有非0元素将会被当作True

numpy 数据存取
	将数据以二进制的格式存储
		存储：np.save('文件名',数据)
		读取：c = np.load('文件名')
	将数据以二进制的格式存储为压缩包
		存储：np.save('文件名', ar0 = 数据a, ar1 = 数据b)
		读取：d = np.load('y.npz') 
			d["ar0"]

CSV文件存取:	Comma-Separated Value

	csv文件只能存储一维、二维数据，不能存储多维数据
	存入：
		np.savetxt(frame, array, fmt='%.18e', delimiter = None)

		frame	
			存储文件、字符串或产生器的名字，可以是.gz或.bz2的压缩文件，对大型数据有用，压缩后存储或读取，节省存储资源
		array	
			存入文件的数组
		delimiter	
			分隔字符串，默认是任何空格，需要改为 逗号
		fmt	写入文件中每个元素的字符串格式
			%s (ASCII字符)
			%d （整数）
			%.2f（2位小数的浮点数）
			%.18e（科学计数法，常用）
				np各类型元素存储到CSV中都是字符串，字符串显示的格式，默认%.18e，科学计数法，保留18位小数的浮点数形式存储数据，需要根据情况修改

		np.savetxt(文件名, 数据, fmt='%.18e', delimiter = None)
	读取：
		np.loadtxt(frame,dtype=np.float,delimiter=None,skiprows=0,usecols=None,unpack=False)

		frame	文件、字符串或产生器，可以是.gz或bz2压缩文件
		dtype	数据类型，可选，CSV的字符串以什么数据类型读入数组中，默认np.float	浮点数
		delimiter	分隔字符串，默认是任何空格，改为 逗号
		skiprows	跳过前x行，一般跳过第一行表头
		usecols	读取指定的列，索引，元组类型
		unpack	如果True，读入属性将分别写入不同数组变量，False 读入数据只写入一个数组变量，默认False

		b = np.loadtxt('a.csv', delimiter=',') # 默认浮点型
		b = np.loadtxt('a.csv', dtype = np.int, delimiter = ',') #数据为整型

		#b = np.loadtxt('a.csv', dtype = np.str, delimiter = ',') #数据为字符串，输出默认带 b，要去掉用下面方式输出：
		b = np.loadtxt('a.csv', dtype = bytes, delimiter = ',').astype(str)
		b = np.loadtxt('a.csv', dtype = bytes, delimiter = ',', skiprows = 1, usecols=(2, 3)).astype(str) #跳过第一行，读入第3、4列

numpy-数组操作:
	排序：
		a = np.random.randint(1, 100, 50)
		np.sort(a)#升序
		-np.sort(-a)#降序

		b = np.random.randint(1, 100, (3, 5))
		np.sort(b, axis = 0) # 0维，按行
		np.sort(b, axis = 1) # 1维，按列

数组转置：a.T
数组转成list：a.tolist()

数组合并：concatenate
	a = np.array([[1,2,3],[4,5,6],[7,8,9]])
	b = np.array([[10,11,12]])

	np.concatenate((a, b), axis = 0)  # 按行拼接
	np.concatenate((a, b.T), axis = 1)  # 按列拼接

数组删除：delete
	a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])
	# 删除行
	b1 = np.delete(a, 1, axis=0) 
	# 删除列
	b2 = np.delete(a, -1, axis=1)  
	# 删除多列
	b3 = np.delete(a, [1,2], axis=1)

高级函数：
	shuffle(a)	
		将数组a的第0轴(最外维度)进行随机排列(洗牌)，改变数组a
	permutation(a)	
		同上，区别是不改变数组a
	.choice(a, size=None, replace=True, p=None)	
		从一维数组a中以概率p抽取元素，形成size形状新数组，replace表示是否可以重用元素，默认为Ture，p为抽取概率

	b = array([266, 126, 997, 528, 321, 370, 124, 157])
	 np.random.choice(b, (3, 2),replace=False, p = b/np.sum(b))
	 -->array([[997, 528],
		       [266, 321],
		       [126, 370]])

numpy集合运算 
	unique(x):去重 排序
	union1d(x,y):合并 去重 排序
	intersect1d(x,y)：交集 去重 排序
	setxor1d(x,y)：交集的反集 
	setdiff1d(x,y)：x-交集
	in1d(x,y)：x是否包含于y 返回布尔数组

	注意：上面的'1'都是数字1不是‘l'

广播机制：
	当两个数组维数不一样进行计算时，会以小就大，小的自动增加维数，进行计算。
	a=array([0, 1, 2, 3, 4])
	b=array([5])
	a+b
	#b = array([5,5,5,5,5])
	c= array([[0, 1, 2, 3, 4],
       		 [5, 6, 7, 8, 9]])
     a+c
     #a=array([[0, 1, 2, 3, 4],
     		   [0, 1, 2, 3, 4]])

矩阵运算：
	x = np.array([[1,2],[3,4]])
	x[0].T 是不能进行转置的
	应该这样：
		x[0].reshape(1,2).T

	矩阵乘法：
		np.dot(x, x)


================Pandas===================================
pandas:最流行的python数据分析库
	基于numpy，专用于数据处理和数据分析的Python第三方库，最适合处理大型结构化表格数据
	是2008年wes mckinney于aqr资本做量化分析师时创建
	借鉴了r的数据结构
	pandas基于numpy搭建，支持numpy中定义的大部分计算
	含有使数据分析工作更加简单高效的高级数据结构和操作工具
	提供了大量和其他技术交互的借口，可视化，方便和其他语言技术的交互和功能扩展
	底层使用了C 提高了执行效率

数据类型：
	Series 		一维，带标签数组
	DataFrame  二维，Series容器（最常用）
	Panel 		三维，DataFrame容器
	
Series:
	一维的，带标签的数组（类似字典）可以用index设置key值
	是ndarray数组的派生类型，和数组比没有类型限制
	由两个numpy数组构成，一组构成对象的键一组构成数组的值
	numpy 中数组运算操作可以用在Series对象
	Python字典操作部分可用于Series

一维创造
	1.a = pd.Series(
			[value]#list value可以是不同类型额数据

			[value],index=[value]

			{key:value}#dict,通过index可以重设key值

			np.arange(5)#通过numpy生成

			g_values = np.arange(5)
			g_index = np.arange(9, 4, -1)
			g = pd.Series(g_values, index = g_index)

	)
一维	读
	index和value查询
		class1.values  输出value的array
		class1.index 	输出index的array
		class1.index[2]  输出指定索引值的index值
	索引查值：
		class1[1]
		class1["huang"]
		class1[[1,2]] #列表里面传列表，注意[]
		class1[['hong','huang']] #
	切片：
		相当于有key:value的列表，和列表的切片一样
一维类似于ndarray的数组运算:
	相当于带上key的array计算
	调用方法有两种写法
		np.median(class1)  # 中位数
		class1.median()  # 方法调用写法
一维类似字典的操作
	'c' in class1 # 判断此键在不在class1的索引中
	class1.get('zi', 60)
		 #从c提取索引zi的值,存在就取出,否则用60代替
一维修改
	类似字典的修改
	class1['ming'] = 0
	class1['hua','hong'] = 55 
		# class1[['hua','hong']] = 20
	class1['hua','hong'] = [35,55]
	修改索引：
		class2 = class1.copy() 
			# 复制副本而非引用视图，类似深拷贝
		class2.index = ['xiaoming','xiaohua','xiaohong','xiaohuang','xiaobai']


DataFrame
	类似excel 
	由多个Series对象作为列组成的表格数据形式，每一行的Series值都增加一个公用的索引
	是Series的容器，可视为带标签数组，或是由Series组成的字典
索引：
	行索引，表明不同行，横向索引，叫index，0轴，axis=0
	列索引，表名不同列，纵向索引，叫columns，1轴，axis=1
其他说明
	基本操作类似于Series，依据行列索引操作
	内存中以一个或多个二维块存放，而不是列表字典或者别的一维数据结构
	常用于表达二维数据，也可以表达多维数组（层次化索引的表格型结构）

二维创造
	d = pd.DataFrame([[],[]],index=[],columns=[])
		#[]为二维数组，index表示行索引，column表示列索引
series组成字典创造
	h_values = {
    'name':pd.Series(['小明','小华','小红','小靑','小兰'],index=[1,2,3,4,5]),
    'sex':pd.Series([1,0,0,1,0],index=[1,2,3,4,5]),
    'age':pd.Series([28,38,48,8],index=[2,3,4,5])  # 少一个值自动填充为NaN
	}
	h = pd.DataFrame(hv)

	# 指定内层字典键（行索引），没有的值会填充NaN
	i = pd.DataFrame(h_values, index=[3,4,2,6])

可以使用numpy里面的二维数组创建
	k = pd.DataFrame(
    np.random.randn(6,4),
    index=[1,2,3,4,5,6],
    columns=['a','b','c','d']
	)

DataFrame构造函数能接收的数据
	字典或series列表（一维）	
		各项成为DataFrame的一行，字典键或series索引的并集成为DataFrame列标
	二维ndarray	
		数据矩阵，还可传入行标和列标
	由列表或元组组成的另一个DataFrame	
		同 二维ndarray
	Numpy的maskedArray（一种可用掩码屏蔽无效值的特殊数组）	
		同 二维ndarray，只是掩码值在结果DataFrame会变成NA/缺失值
	由数组、列表或元组组成的字典	
		每个序列会成为DataFrame的一列，注意：所有序列长度必须相同
	嵌套字典(由字典组成的字典)	
		各内层字典成为一列，如没指定索引，键会合并成结果的行索引
	由Series组成的字典	同 
		嵌套字典

查询一般属性：
	a.shape  #多少行多少列
	a.dtypes  # 每个列的属性int object
	a.index  # 行索引值
	a.columns  # 列索引值
	a.values  # 对象值，二维ndarray数组，具体的数据

查询整体情况：
	a.head(3)  # 显示头部几行，默认5行
	a.tail(3)  # 显示末尾几行，默认5行
	a.info()  # 相关信息概览：行数，列数，列索引，列非空值个数，列类型，列类型，内存占用
	a.describe()  #快速综合统计结果：计数，均值，标准差，最大值，四分位数，最小值

类list/ndarray查询方式：注意 先列后行
	列：
		a['name']
		a.name  # .写法容易与其他预留关键字产生冲突,不推荐
		a[['name','address']]  # 双中括号，查询多列
	行：	
		a[:2]  # 0，1行
		a[1:2]  # 1行
		a[2:5:2]  # 2、4行
	单值：
		a['name'][2]  # 先列后行

pandas三种专用查询：
	索引：注意先行后列
		a.loc[行,列]，标签索引，自定义索引 ，按索引值
		a.at[] 同上，效率更快
		a.iloc[行,列]，位置索引，默认索引
		a.iat[]同上效率更快

		a.loc[1]  # 标签索引
		a.iloc[1]  # 位置索引，从0开始

		# 查询单列
		a.loc[:,'name']  # 标签索引
		a.iloc[:,0]  # 位置索引

		# 查询多行，双中括号
		a.loc[[2,4]]  # 标签索引
		a.iloc[[1,3]]  # 位置索引

		# 查询多列
		a.loc[:,['name','address']]  # 标签索引
		a.iloc[:,[0,5]]  # 位置索引

		# 查询单个单元格
		a.loc[1,'name']  # 标签索引，先行后列，一行一列
		a.at[1,'name']  # 同上，但速度更快效率更高

		a.iloc[0,0]  # 位置索引
		a.iat[0,0]  # 同上，但速度更快效率更高

		# 查询多个单元格
		a.loc[1,['name','address']]  # 一行多列，Series
		a.loc[[1,3],'address']  # 多行一列，Series
		a.loc[[1,3],['name','address']]  # 多行多列，不连续，DataFrame

		a.iloc[0,[0,5]]
		a.iloc[[0,2],5]
		a.iloc[[0,2],[0,5]]

	切片：索引查询简单方便，但不能查询非连续行列区块
		# 选取一行
		a.loc[2,:]  # 等价于 a.loc[2]
		a.iloc[1,:]  # 等价于 a.iloc[1]

		# 选取一列
		a.loc[:,'sex']
		a.iloc[:,1]

		# 切片选取连续多行
		a.loc[:3,:]  # 左闭右闭
		a.iloc[:3,:]  # 左闭右开

		# 切片选取连续多列
		a.loc[:,'heigh':'address']
		a.iloc[:,3:6]

		# 切片选取多行多列的聚合
		a.loc[3:5,'sex':'heigh'] 
		a.iloc[2:5,1:4]

	过滤：通过列布尔值过滤、筛选查询
		# 通过某列值过滤数据，返回布尔值
		a['grade'] >= 60
		a.loc[:,'grade'] >= 60

		# 布尔值做DataFrame参数，返回Dataframe对象
		a[a['grade'] >= 60]
		a[a.loc[:,'grade'] >= 60]

		# 布尔索引和切片结合
		a.loc[a['grade'] > 60,'address':]  # 行，列

		#与或非
		(a['grade'] >= 60) & (a['sex'] == 'female')
		a[(a['grade'] >= 60) & (a['sex'] == 'female')]

	过滤数据：
		a > 60 #返回布尔值
		a < 30	

		a[a > 60] #Ture 返回 FALSE不返回
		a[a < 30]

		# where过滤
		dColumns = a[['name','weight','grade']]  
			# 获取3列数据
		dBool = dColumns > 60  # 判断布尔值
		dNan = dColumns[dBool]  # 过滤查询
		dNan.dropna(how='any')  # 丢掉含有缺失值的行

	isin 通过条件返回整条数据
		a['address'].isin(['北京海淀','深圳南山'])
			#返回Ture False
		a[a['address'].isin(['北京海淀','深圳南山'])]
			#返回确定的值

	修改：基本上查到给它赋值就可以
		b['heigh'] = [150,160,170,180,190] 
			右边只写一个值就表示全都赋上这个值
		b.loc[[1,3,5],['age','heigh']] = [[10,100],[20,200],[30,300]] # 3行2列

		注意：当查出的数据是混合型数据的时候是不能修改值的
			b[b > 60] = 1 # 错误，不能在混合数据类型中修改非NaN值

		# 提取唯一数据类型数据
		c = a.loc[:,['weight','grade']].copy()
		c2 = c.copy()

		-(c2 > 60) # 非，或 c2 <= 60  '-'表示取反

 
增加 add

	为不存在的行或列索引赋值会创建新行列
	series:
		s = pd.Series([1,2,3,4,5])
		s[6] = 10
		s['username'] = 'Amber'
		s.index
	dataframe:
			# 创建对象
		a_values = [
		    ['小明','male',18,170,60,'北京海淀',61],
		    ['小华','female',28,160,50,'上海静安',74],
		    ['小红','female',22,175,64,'广州天河',59],
		    ['小靑','male',31,182,80,'深圳南山',82],
		    ['小兰','female',25,165,55,'杭州西湖',98],
		]

		a = pd.DataFrame(
		    a_values,
		    index=[1,2,3,4,5],
		    columns=['name','sex','age','heigh','weight','address','grade']
			)
		#增加列
			b['chinese'] = [50,60,70,80,90]
		#增加行
			b.loc['aaa'] = ['小芳','female',24,164,52,'美国加州',95,80,90]

delete 删除
	Series：drop()
		s2 = s.drop('ming')
	dataframe:
		# 默认删除行，默认只改动视图
		b.drop(1) # 删除单行
		b.drop([1,7]) # 删除多行

		# 删除列
		# axis=1删除列，默认axis=0删除行
		b.drop('math',axis=1)
		b.drop(['math','chinese'],axis=1)
		b

		# inplace=True 改动原数据，默认inplace=False 只改动视图
		b.drop(['math','chinese'],axis=1,inplace=True)

.name 命名  相当于excel中给第一行和第一列命名
	series:	
		s.name = 'uname'
		s.index.name = 'cname' 
	dataframe:
		b.index.name = 'hang'
		b.columns.name = 'lie'

遍历dataframe:
	for index, row in a.iterrows():
	    print(index) # 行索引
	    print(row) # 值，按行排列
	    print(row[0]) # 单元格

pandas数据存取(csv)：
	写入：to_csv()
		a.to_csv('foo.csv')
		a.to_csv(
			    'foo2.csv', # 存入数据
			    index=False, # 不存储行索引
			    header=False, # 不存储列索引
			    encoding='utf-8' # 修改编码
				)
	读取：read_csv()
		pd.read_csv('foo.csv')
		pd.read_csv(
		    'foo2.csv', # 文件名
		    sep=',', # 指定分隔符，csv默认逗号，如果是table表格数据一般为 \t
		    usecols=[0,1,2,4], # 读取指定列
		    nrows=10, # 读取前几行
		    header=None, # 不将第一行设为表头
		    names=['a','b','c','d'], # 不使用csv表头，自定义表头
		    encoding='utf-8' # 编码，需要根据文本编码修改，默认utf-8,可以指定为GBK/ascii
		)
		csv文件内有汉字等特殊符号时，csv文件编码应为utf-8(无BOM)可默认正常读取，如果编码是ANSI，加参数encoding='gbk'
		数据内有逗号时，左右加英文半角双引号，可以正常解析

		将某列设为行索引：
			 index_col='shijian', 

xlsx存取：
	写入：需要装这个模块：openpyxl
		a.to_excel('foo.xlsx', sheet_name='Sheet1')
	读取：需要装这个模块：xlrd
		pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])

	将多个dataframe写到不同的excel sheet中
		writer = pd.ExcelWriter('output.xlsx')#创建表对象
		df.to_excel( #表1
				    writer, # 写入数据
				    'Sheet1', # 工作表标签
				    header=False, # 不存入列索引
				    index=False # 不存入行索引
				)
		a.to_excel(writer,'Sheet2') #表2
		writer.save() #提交
	分别读取：
			# 不将第一行设为表头	
		pd.read_excel('output.xlsx', 'Sheet1', index_col=None, na_values=['NA'],header=None) 	
			
		pd.read_excel('output.xlsx', 'Sheet2', index_col=None, na_values=['NA'])


MySQL 存取：
	读取：
		pd.io.sql.read_sql()	
	写入：
		pd.io.sql.to_sql()
	注意：
		to_sql()是直接调用的INDERT语句完成任务，传输速度比较慢，
		如果想传入大型数据框，最好先导出csv文件再导入数据库中。

	from sqlalchemy import create_engine

	# 连接MySQL数据库，需要安装Python连接库
	# conda install -c anaconda pymysql 

	dbconnect = 'pymysql' # MySQL连接库，根据使用的连接库修改名称，这里用pymysql
	dbname = 'aaa' # 数据库名
	dbusername = 'root' # 数据库用户名
	dbpwd = 'root' # 数据库密码

	# 连接数据库
	conn = create_engine('mysql+' + dbconnect + '://' + dbusername + ':' + dbpwd + '@localhost:3306/' + dbname + '?charset=utf8')
	# 查询数据库

	sql1 = 'SELECT * FROM ccc'

	df1 = pd.read_sql( # pd.io.sql.read_sql()的快捷方式
	    sql1, # sql语句
	    conn, # 数据库连接
	    index_col='id' # 选定某列做行索引，可选
	)
	df1

	pd.io.sql.to_sql(
	    a, # 插入的数据，注意格结构应和MySQL表一致
	    'ccc', # 表名
	    con=conn, # 数据库连接
	    if_exists='append', # 注释见下
	    index=False # 不将列索引插入数据库中，否则会出错
	)

	if_exists参数：
		fail	默认值，如果表存在，报错，什么都不做
		append	如果表存在，追加数据，如果表不存在创建一个表
		replace	如果表存在，删了表，再建立一个新表，把数据插入


json存取：
	# 存入JSON
	a.to_json('foo.json')
	# 读取JSON
	pd.read_json('foo.json')	

pkl存取:
	# 存入pickle
	a.to_pickle('a.pkl')

	# 读取pickle
	a_pkl = pd.read_pickle('a.pkl')

HDF5存取：
	df.to_hdf('foo.h5','df')
	pd.read_hdf('foo.h5','df')
	a.to_hdf('foo.h5','abc')
	pd.read_hdf('foo.h5','abc')

从剪贴板读取：
	pd.read_clipboard()
	pd.read_clipboard(header=None) # 不将第一行设为表头

基本统计分析方法：（都是按列算的）
	.describe()	
		针对0轴(列)的统计汇总，计数/平均值/标准差/最小值/四分位数/最大值
	.sum()	
		计算数据的总和,按0轴计算(各行计算),下同,要按列计算参数1
	.count()	
		统计每一列的个数非NaN值数量
	.mean() .median() .mode()	
		计算数据的算数平均值/中位数/众数
	.var() .std()	
		计算数据的方差/标准差
	.min() .max()	
		计算数据的最小值/最大值
	.idxmin() .idxmax()	
		计算数据第一个最大值/最小值所在位置的索引，给索引或切片使用(自定义索引，排除null/NA等空值)

	只适用于Series的方法：
		.argmin() .argmax()	
			计算数据第一个最大值/最小值所在位置的索引位置

	b.sum()  # 按列求和
	b.sum(axis = 1)

	a.argmin()  # Series返回最小值的索引
	b.idxmin()  # Dataframe返回每列最小值的行索引

	a.describe()
	type(a.describe()) # series对象
	a.describe()['count']

	b.describe()  #默认0轴运算
	type(b.describe())  # dataframe对象

	# 返回横行数据,series
	b.describe().loc['max']
	b.describe().iloc[7]

	# 返回一列值
	b.describe()[2]
	b.describe().loc[:,2]

自定义运算：
	series:map()
		def f(x):
			return x+5-2
		a.map(f)
	DataFrame:apple()
		def f(x):
		    return pd.Series([x.min(), x.max()], index=['min', 'max'])
		b.apply(f)  # 默认按列运算
		b.apply(f, axis=1)  # 按行运算

		将自定义函数应用到DataFrame对象每个值上:
			def f(x):
			    d = x + 1 - 2 * 3 / 4
			    return d

			b.applymap(f)

累计统计分析：
	.cumsum()	依次给出前1/2/.../n个数的和
	.cumprod()	依次给出前1/2/.../n个数的积
	.cummax()	依次给出前1/2/.../n个数的最大值
	.cummin()	依次给出前1/2/.../n个数的最小值

滚动计算（窗口计算）函数
	.rolling(w).sum()	依次计算相邻w个元素的和
	.rolling(w).mean()	依次计算相邻w个元素的算数平均值
	.rolling(w).var()	依次计算相邻w个元素的方差
	.rolling(w).std()	依次计算相邻w个元素的标准差
	.rolling(w).min .max()	依次计算相邻w个元素的最小值/最大值

	b.rolling(2).sum()  # 纵向列,以两个元素为单位,做求和运算
	b.rolling(3).sum()

分组聚合：
	数据分析第一步就是计算分组统计
	Pandas支持运算的数据种类比sql多而且强大

	分组：groupby() 就好像Excel合并单元格
		Splitting 将数据分组
		Applying 对每个分组应用不同的function
		Combining 使用某种数据结果展示结果

				# 分组数据的个数
		df.groupby('name').size()

		# 遍历分组对象
		for (method, group) in df.groupby('name'):
		#     print(method)
		#     print(group)
		    print(group.shape)

		# 对分组后的部分列做统计
		df.groupby('name')['math'].describe()
		# 行列旋转
		df.groupby('name')['math'].describe().unstack()

	聚合：aggregate()，或agg()
		参数可以是列表，列表元素是指标的计算函数或特定的指标名字符串
		参数可以是字典，函数会根据字典内容对指定列进行不同的指标计算
		参数可以是系统或自定义函数，各分组都进行计算后返回结果

		d = df.groupby('name').aggregate([min,max,np.mean])
		#分组后 显示每一列的最大值最小值平均值

		df.groupby('name').aggregate({'chinese':'min','math':'max'})
		#分组后，显示每组语文的最小值和数学的最大值

		自定义聚合函数：agg()
			def hs(arr):
			    return arr.mean()-1

			df.groupby('name').agg(hs)

	分组后筛选：filter
		def filter_func(x):
		    return x['math'].mean() >= 60 # 数学成绩平均值大于等于60分

		e = df.groupby('name').filter(filter_func)
		e.groupby('name').mean()

	对所有元素进行转换计算
		df.groupby('name').transform(lambda x: x - 60)
		#df中所有的元素都减去60

	对所有分组进行不同规则的计算
		def a2(x):
		    x['chinese'] = x['chinese'] + 10
		    x['english'] -= 10
		    return x

		df.groupby('name').apply(a2)

	在 groupby 函数的输入中自定义分配每一行记录所属的分组

	如果我们的输入就是原始数据集 df 中的某一列，那么这一列将被作为分组的依据，这种方法比直接输入列名要麻烦一些

	# 传入结构一样的列，传入索引会替换掉原索引
	df.groupby(['张三','李四','王五','李四','王五','王五','张三']).mean()
	df.groupby([0,0,0,0,0,0,0]).mean()

	unstack() 不要堆叠
	stack() 堆叠
	fillna()  NaN缺失值，用其他值代替NaN

	# 所有人在所有测试中的数学成绩
	df.groupby(['name',df['test']])['math'].mean().unstack().fillna(0)

数据规整：
	数据分析和建模绝大多数工作都是用在数据准备上的，一般获取到的存放在文件或数据库中的数据并不能满足数据处理应用的要求

	pandas提供了一组高级灵活高效的核心函数和算法，能够轻松的将数据规整化为你需要的形式

	规整的一般方法：
		清理
		转换
		合并

清理：含有None的数组等不能直接进行运算
	在numpy 中使用numpy.nan代表缺失数据，含有np.nan的数据虽然空值部分不能执行运算
	a.sum(), a.min(), a.max() # 全部返回nan
	np.nansum(a), np.nanmin(a), np.nanmax(a) # 返回理想值

	在pandas中不论是None还是Nan都会转化为NaN的形式
	NaN：非数字，not a number，Pandas中它表示缺失或NA值，便于被检测出来
	本质上就是np.nan

	Pandas的对象可以跳过缺失值直接进行运算

检测是否有缺失值：
	# 返回布尔值，缺失值为True
	b.isnull()
	# 返回布尔值，缺失值为False
	b.notnull()
	# 手工过滤缺失值
	b[b.notnull()]

去掉缺失值，只保留有效值：dropna()
	# 默认按行去除
	c.dropna()
	c.dropna(axis = 'columns')
	# how='all',行或列所有元素都为缺失值才去除
	# how='any',行或列出现一个缺失值即去除，默认值
	c.dropna(axis = 'columns', how = 'all')
	# 行或列的非缺失值大于等于thresh值才保留，否则去除
	c.dropna(thresh = 3)

填补缺失值 fillna()
	# 缺失值填补为固定值
	b.fillna(1)
	# 特别功能，缺失值填补为均值
	b.fillna(b.mean())
	# 向前填补（forward-fill），默认值，使用缺失值前一个值填补
	b.fillna(method = 'ffill')
	# 向后填补（back-fill）
	b.fillna(method = 'bfill')
	 # 按行填补 
	c.fillna(method = 'ffill', axis = 1)
	# 如果通过字典调用fillna，可对不同列填充不同值
	c.fillna({0:0.5,1:-1})
	# 操作默认返回副本，也可以直接修改源数据
	b2.fillna(0,inplace = True)
	# limit连续填充数量设置
	c.fillna(method = 'ffill', limit = 2)

替换值：replace()
	# 将-999替换为pandas能理解的NA值
	data.replace(-999, np.nan)
	# 一次性替换多个值
	data.replace([-999,-1000], np.nan)
	# 对不同的值进行不同的替换
	data.replace([-999,-1000], [np.nan,0]) # 对应结构的列表
	data.replace({-999:np.nan, -1000:0}) # 字典

映射数据值：map()
	a = pd.DataFrame([['鬃刷','皮带','煎蛋','观赏'], [10,20,30,40]]).T
	b = {'鬃刷':'猪','皮带':'牛','毛衣':'羊','观赏':'鱼'}

	# 将DataFrame列值转为字典映射值,如果不对应就返回NaN
	a[0].map(b)

移除重复数据：duplicated()
	# 布尔型Series,各列重复值交集，行与行之间重复才重复
	data.duplicated()

	# 移除重复行
	data.drop_duplicates()
	data[-(data.duplicated())] # 用布尔索引也可以

	# 移除自定义列重复行
	data.drop_duplicates('k1')

	# first默认留下第一次出现的值
	data.drop_duplicates(['k1', 'k2'],keep = 'first')
	# last,留下最后一次出现的值
	data.drop_duplicates(['k1', 'k2'],keep = 'last')
	# False,删掉所有重复值
	data.drop_duplicates(['k1', 'k2'],keep = False)

pandas整数规整-转换
























